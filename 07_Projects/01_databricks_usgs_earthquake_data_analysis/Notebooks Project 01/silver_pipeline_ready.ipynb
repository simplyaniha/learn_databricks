{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f42e04f8-2ecb-48fd-8bc3-751cf386a6e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Mount ADLS Gen2\n",
    "# # Required each time the cluster is restarted which should be only on the first notebook as they run in order\n",
    "\n",
    "# tiers = [\"bronze\", \"silver\", \"gold\"]\n",
    "# adls_paths = {tier: f\"abfss://{tier}@yagamiazdbsa.dfs.core.windows.net/\" for tier in tiers}\n",
    "\n",
    "# # Accessing paths\n",
    "# bronze_adls = adls_paths[\"bronze\"]\n",
    "# silver_adls = adls_paths[\"silver\"]\n",
    "# gold_adls = adls_paths[\"gold\"] \n",
    "\n",
    "# dbutils.fs.ls(bronze_adls)\n",
    "# dbutils.fs.ls(silver_adls)\n",
    "# dbutils.fs.ls(gold_adls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e33b1fa5-5b55-46f3-865a-1866f5112929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from datetime import date, timedelta\n",
    "# start_date = date.today() - timedelta(days=1)\n",
    "# end_date = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2bc50e-742f-4575-b86f-fd6cc33a4dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-7012751062707529>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m bronze_output \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mtaskValues\u001B[38;5;241m.\u001B[39mget(taskKey\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbronze\u001B[39m\u001B[38;5;124m\"\u001B[39m, key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbronze_output\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      3\u001B[0m start_date \u001B[38;5;241m=\u001B[39m bronze_output\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_date\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m end_date \u001B[38;5;241m=\u001B[39m bronze_output\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_date\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:254\u001B[0m, in \u001B[0;36mDBUtils.JobsHandler.TaskValuesHandler.get\u001B[0;34m(self, taskKey, key, default, debugValue)\u001B[0m\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNotInJobContextException\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m exceptionClassName:\n",
       "\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debugValue \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n",
       "\u001B[1;32m    255\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMust pass debugValue when calling get outside of a job context. debugValue cannot be None.\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[1;32m    256\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m debugValue\n",
       "\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Must pass debugValue when calling get outside of a job context. debugValue cannot be None."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "Must pass debugValue when calling get outside of a job context. debugValue cannot be None."
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-7012751062707529>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m bronze_output \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mtaskValues\u001B[38;5;241m.\u001B[39mget(taskKey\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbronze\u001B[39m\u001B[38;5;124m\"\u001B[39m, key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbronze_output\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m start_date \u001B[38;5;241m=\u001B[39m bronze_output\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_date\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m end_date \u001B[38;5;241m=\u001B[39m bronze_output\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_date\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:254\u001B[0m, in \u001B[0;36mDBUtils.JobsHandler.TaskValuesHandler.get\u001B[0;34m(self, taskKey, key, default, debugValue)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNotInJobContextException\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m exceptionClassName:\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debugValue \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    255\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMust pass debugValue when calling get outside of a job context. debugValue cannot be None.\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    256\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m debugValue\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mTypeError\u001B[0m: Must pass debugValue when calling get outside of a job context. debugValue cannot be None."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bronze_output = dbutils.jobs.taskValues.get(taskKey=\"bronze\", key = \"bronze_output\")\n",
    "\n",
    "start_date = bronze_output.get(\"start_date\", \"\")\n",
    "end_date = bronze_output.get(\"end_date\", \"\")\n",
    "\n",
    "bronze_adls = bronze_output.get(\"bronze_path\", \"\")\n",
    "silver_adls = bronze_output.get(\"silver_path\", \"\")\n",
    "\n",
    "print(f\"Start date: {start_date}\")\n",
    "print(f\"End date: {end_date}\")\n",
    "print(f\"Bronze ADLS: {bronze_adls}\")\n",
    "print(f\"Silver ADLS: {silver_adls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "133de57d-897e-4f98-8a2c-f1da6a50a805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnull, when\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Load the JSON data into a Spark DataFrame\n",
    "df = spark.read.option(\"multiline\", \"true\").json(f\"{bronze_adls}{start_date}_earthquake_data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1cc0595-1b11-484d-a0c8-cedc1ac8641e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "578aaa8a-0bc3-4a12-bd53-47adf54ee452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64b44125-a6cb-4d3a-ad10-e5e6f0d686cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reshape earthquake data\n",
    "df = (\n",
    "    df\n",
    "    .select(\n",
    "        'id',\n",
    "        col('geometry.coordinates').getItem(0).alias('longitude'),\n",
    "        col('geometry.coordinates').getItem(1).alias('latitude'),\n",
    "        col('geometry.coordinates').getItem(2).alias('elevation'),\n",
    "        col('properties.title').alias('title'),\n",
    "        col('properties.place').alias('place_description'),\n",
    "        col('properties.sig').alias('sig'),\n",
    "        col('properties.mag').alias('mag'),\n",
    "        col('properties.magType').alias('magType'),\n",
    "        col('properties.time').alias('time'),\n",
    "        col('properties.updated').alias('updated')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd54bab-2f4b-43f9-b13a-c2ad7f542541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1c6b56e-cea9-423a-857d-f3fce942d5e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Validate data: Check for missing or null values\n",
    "df = (\n",
    "    df\n",
    "    .withColumn('longitude', when(isnull(col('longitude')), 0).otherwise(col('longitude')))\n",
    "    .withColumn('latitude', when(isnull(col('latitude')), 0).otherwise(col('latitude')))\n",
    "    .withColumn('time', when(isnull(col('time')), 0).otherwise(col('time')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56d48af-15c0-44fc-b22f-570295025aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'time' and 'updated' to timestamp from Unix time\n",
    "df = (\n",
    "    df\n",
    "    .withColumn('time', (col('time') / 1000).cast(TimestampType()))\n",
    "    .withColumn('updated', (col('updated') / 1000).cast(TimestampType()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "668ee336-1c08-4c8c-8926-7757ef1a93ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b099c99e-8dee-41d7-9be1-7a1d557e3c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Save the transformed DataFrame to the Silver container\n",
    "silver_output_path = f\"{silver_adls}earthquake_events_silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e204be8-8f35-4866-8e9f-4cc94d67323a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Append DataFrame to Silver container in Parquet format\n",
    "df.write.mode('append').parquet(silver_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34898338-a7f1-4c5b-b3a4-ae607c994178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set task values for workflow\n",
    "dbutils.jobs.taskValues.set(key=\"silver_output\", value=silver_output_path)\n",
    "print(\"Silver notebook completed successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b43f90e1-437b-4089-9859-8903ea8f2711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}